{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "passing-trouble",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_df = pd.read_csv(\"../files/sentiment_dataset/TrainingDatasets/TrainTema.csv\",sep=';')\n",
    "#test_df = pd.read_csv(\"../files/sentiment_dataset/TestDatasets/TestTema.csv\",sep=\";\")\n",
    "#train_df = [ [txt,snt] for txt,snt in zip(train_df.iloc[:,1],train_df.iloc[:,3]) ]\n",
    "#test_df = [ [txt,snt] for txt,snt in zip(test_df.iloc[:,1],test_df.iloc[:,3]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ba8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98062109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../files/sentiment_dataset/TrainingDatasets/TrainTema.csv\",sep=';')\n",
    "df = df.iloc[:,[3,1]]\n",
    "df.columns = ['label', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a1b797b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7a1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "# we will use temp_text and temp_labels to create validation and test set\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66e17fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f2a5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 10372, 10127, 143, 40668, 10713, 85809, 17333, 102, 0], [101, 11312, 11229, 12922, 118, 51301, 143, 40668, 10713, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# sample data\n",
    "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
    "\n",
    "# encode text\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)\n",
    "print(sent_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "284dc37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4beaa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c477d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8127486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9acaf7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1aeeca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "006dc69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "\n",
    "        self.bert = bert \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "\n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "\n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3db9b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a964a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cc58d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renan/ic/tm_er/venv/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=23855    1\n",
      "34517    0\n",
      "33352    0\n",
      "7270     1\n",
      "9246     1\n",
      "        ..\n",
      "1366     1\n",
      "47773    0\n",
      "16128    1\n",
      "4396     1\n",
      "9945     1\n",
      "Name: label, Length: 35000, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
    "\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cd9f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0d874a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "\n",
    "        # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds)\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62898ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "\n",
    "    print(\"\\nEvaluating...\")\n",
    "\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "\n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fa7d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c5138ddf6b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-152ff43f7264>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# get model predictions for the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# compute the loss between actual and predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ic/tm_er/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-abf09036757f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ic/tm_er/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ic/tm_er/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ic/tm_er/venv/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea1da35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
